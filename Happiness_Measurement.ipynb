{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true
      },
      "cell_type": "code",
      "source": "train_df = pd.read_csv('../input/train_hp.csv')\ntrain_df.head()\n\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "23a2e126b7a30422f54670debce2b3e4fe63b699"
      },
      "cell_type": "code",
      "source": "test_df = pd.read_csv('../input/test_hp.csv')\ntest_df.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "8dff03859726ee90f1dc1e03e598314bc21c4edb"
      },
      "cell_type": "code",
      "source": "train_df = train_df.drop(['User_ID'],axis=1)\ntrain_df.Browser_Used.unique()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "09058d91f6e7424c68be8b14b6d7ab8b81786310"
      },
      "cell_type": "code",
      "source": "train_df.Browser_Used.unique()\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1068ab068b07de0bed4831471d60240493a3531a"
      },
      "cell_type": "code",
      "source": "test_df.Browser_Used.unique()\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a90b782173a21c8f6f6e96dd8063c1f491fad484"
      },
      "cell_type": "code",
      "source": "train_df.Device_Used.unique()\ntrain_df.head()\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "2816bb80fb4e2b628f434c6580a2ecdd9308072d"
      },
      "cell_type": "code",
      "source": "test_df.Device_Used.unique()\ntest_df.head()\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "5ffc9d34c83a6cdfc1649b4306e226eaaa5f6b48"
      },
      "cell_type": "code",
      "source": "ip_addresses = train_df.Browser_Used.unique()\nip_dict1 = dict(zip(ip_addresses, range(len(ip_addresses))))\ntrain_df = train_df.replace(ip_dict1)\n\nip_addresses = train_df.Device_Used.unique()\nip_dict2 = dict(zip(ip_addresses, range(len(ip_addresses))))\ntrain_df = train_df.replace(ip_dict2)\n\ntrain_df.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "80f77fdd293881a577b75d2fefe181071aedd701"
      },
      "cell_type": "code",
      "source": "ip_addresses = test_df.Browser_Used.unique()\nip_dict1 = dict(zip(ip_addresses, range(len(ip_addresses))))\ntest_df = test_df.replace(ip_dict1)\n\nip_addresses = test_df.Device_Used.unique()\nip_dict2 = dict(zip(ip_addresses, range(len(ip_addresses))))\ntest_df = test_df.replace(ip_dict2)\n\ntest_df.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "eec0b7758c1a3cbbcbca14b99fa53ef4a5e260a2"
      },
      "cell_type": "code",
      "source": "test_df['Browser_Used'] = test_df['Browser_Used']+1\ntest_df['Device_Used'] = test_df['Device_Used']+1\ntest_df.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b7b397725c84bdcc8a9fcd24f8ddccf016e50724"
      },
      "cell_type": "code",
      "source": "train_df['Browser_Used'] = train_df['Browser_Used']+1\ntrain_df['Device_Used'] = train_df['Device_Used']+1\ntrain_df.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "2282ba968a4d82b8b99a6e915a0688ab76a4408f"
      },
      "cell_type": "code",
      "source": "ip_addresses = train_df.Is_Response.unique()\nip_dict3 = dict(zip(ip_addresses, range(len(ip_addresses))))\ntrain_df = train_df.replace(ip_dict3)\ntrain_df.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "5a32f13fa28483dab8e8a0cead048cbc48483b60"
      },
      "cell_type": "code",
      "source": "# Starting with the CountVectorizer/TfidfTransformer approach...\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfTransformer\ncvec = CountVectorizer(stop_words='english', min_df=.0015, max_df=.4, ngram_range=(1,2))\ncvec",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e097451aa239e016d8dcd45335fd2c911170d8ba",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b3d967d362195b8a84ba3f48a2a1561f7f18c556",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3694dcd937f954c97909e6d6415ab717421a9ef5"
      },
      "cell_type": "code",
      "source": "cvec.fit(train_df['Description'].values)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a9a689a3a4f8b3bbfbb01bba6ced31c572222a22"
      },
      "cell_type": "code",
      "source": "len(cvec.vocabulary_)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d2ea86727a8a362249139b2712326f57279af93f"
      },
      "cell_type": "code",
      "source": "cvec_counts = cvec.transform(train_df['Description'])\nprint('sparse matrix shape:', cvec_counts.shape)\nprint('nonzero count:', cvec_counts.nnz)\nprint('sparsity: %.2f%%' % (100.0 * cvec_counts.nnz / (cvec_counts.shape[0] * cvec_counts.shape[1])))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "887e3e50e57b63f6addf2aef09ba314af7161aaf"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "48f1683db7ff7a9308a260fed33530c685ae6b41"
      },
      "cell_type": "code",
      "source": "occ = np.asarray(cvec_counts.sum(axis=0)).ravel().tolist()\ncounts_df = pd.DataFrame({'term': cvec.get_feature_names(), 'occurrences': occ})\ncounts_df.sort_values(by='occurrences', ascending=False).head(20)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "5880e678b5f7ef0d420e6b919db785109903f576",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1b37679a1dc5cf31e8915cc867e3776b2d3da1bc"
      },
      "cell_type": "code",
      "source": "# using the TfidfTransformer to calculate the weights for each term in each document \n\ntransformer = TfidfTransformer()\ntransformed_weights = transformer.fit_transform(cvec_counts)\ntransformed_weights",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "50e0510d9b7cf4deaf8119bfea0232844b3876c6"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "8ab16c7feb7fd2969afe32820c35bbcd5d75297a"
      },
      "cell_type": "code",
      "source": "# top 20 terms by average tf-idf weight:\nweights = np.asarray(transformed_weights.mean(axis=0)).ravel().tolist()\nweights_df = pd.DataFrame({'term': cvec.get_feature_names(), 'weight': weights})\nweights_df.sort_values(by='weight', ascending=False).head(20)\n\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0e7cd8d3efab8305a54deaddb44cf9c0635f6baf"
      },
      "cell_type": "code",
      "source": "# using the TfidfVectorizer class\nfrom sklearn.feature_extraction.text import TfidfVectorizer\ntvec = TfidfVectorizer(min_df=.0015, max_df=.4, stop_words='english', ngram_range=(1,2))\ntvec_weights = tvec.fit_transform(train_df['Description'])\nweights = np.asarray(tvec_weights.mean(axis=0)).ravel().tolist()\nweights_df = pd.DataFrame({'term': tvec.get_feature_names(), 'weight': weights})\nweights_df.sort_values(by='weight', ascending=False).head(20)\n\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "5fbd7ef03dbeead262683e751a0f0b201b2a48d4",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f7eaeed7e021df1d889c2fe3c905b2287ac78fbb"
      },
      "cell_type": "code",
      "source": "tvec_weights.shape",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "7cdae367bca3249b224bd65b11a542d0af266dc9"
      },
      "cell_type": "code",
      "source": "X_train = tvec_weights[:35000]\ny_train = train_df['Is_Response'][:35000]\n\nX_test = tvec_weights[35000:]\ny_test = train_df['Is_Response'][35000:]\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "a35bfe70e8dacd1ec26d604adc0d132f2f8958b9"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a74cdbd3b047c9f5ea6736d941c6eb418e510bd4"
      },
      "cell_type": "code",
      "source": "# Naive bayes Model\nfrom sklearn.naive_bayes import MultinomialNB\nclf = MultinomialNB().fit(X_train, y_train)\n\n\n\npredicted = clf.predict(X_test)\nnp.mean(predicted == y_test)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e55f088cfaa9f8e1a12553bdca6ddb2d90a4e06b"
      },
      "cell_type": "code",
      "source": "from sklearn.ensemble import RandomForestClassifier\nclassifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\nclassifier.fit(X_train, y_train)\n\n\npredicted_RandomForestClassifier = classifier.predict(X_test)\nnp.mean(predicted_RandomForestClassifier == y_test)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "90e57f02f5b1967d1a09c5ec0606229669932ebd"
      },
      "cell_type": "code",
      "source": "# using xgboost classifier\nfrom xgboost import XGBClassifier\n# fit model into training data\nmodel = XGBClassifier()\nmodel.fit(X_train, y_train)\ny_pred = model.predict(X_test)\nnp.mean(y_pred == y_test)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b49ad42744c0fd745051bcfa23ba40ed114f0001"
      },
      "cell_type": "code",
      "source": "from sklearn.linear_model import LogisticRegression\nsmreg_model = LogisticRegression(multi_class=\"multinomial\", solver='lbfgs')\n\nsmreg_model.fit(X_train, y_train)\n\npredicted_LR = smreg_model.predict(X_test)\nnp.mean(predicted_LR == y_test)\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a7c7b487555f1eb6af7d430390c68375ae9677eb"
      },
      "cell_type": "code",
      "source": "test_df.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "e9537b6aaa4434d55bf4403a7e72f5853d4f63cb"
      },
      "cell_type": "code",
      "source": "cvec_t_counts = cvec.transform(test_df['Description'])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "853a5aeab992ad0134c0b73434471aaca42e4e43"
      },
      "cell_type": "code",
      "source": "len(cvec.vocabulary_)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e9b024b8e9b933c8969c05c207a947244c0af57b"
      },
      "cell_type": "code",
      "source": "cvec_t_counts = cvec.transform(test_df['Description'])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "5cc5fb69744b24b69cfc9486ac198d9a36b8dab1"
      },
      "cell_type": "code",
      "source": "print('sparse matrix shape:', cvec_t_counts.shape)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "243d53980f58032be1e2960e61560246d91c3243"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "7dede4dbb93eda51442a3e140e6d5aa9417cd5ee"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "84e720b654f2d5f8a56655f447788869c729b3ab"
      },
      "cell_type": "code",
      "source": "X_Test=cvec_t_counts",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "0a3b2715c33c8318732f3457601a0ea892bcd62f"
      },
      "cell_type": "code",
      "source": "from sklearn.linear_model import LogisticRegression\nsmreg_model = LogisticRegression(multi_class=\"multinomial\", solver='lbfgs')\n\nsmreg_model.fit(X_train, y_train)\n\npredicted_LR = smreg_model.predict(X_Test)\n\n\nsub = pd.DataFrame()\nsub['User_ID'] = test_df['User_ID']\nsub['Is_Response'] = predicted_LR\nsub\n\ndict = {1:'happy',0:'not_happy'}\nsub = sub.replace(dict)\nsub\n\nsub.to_csv('output.csv')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "98dfc4506732fbf51a509f0e886c1d72f9cfbc37"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}